{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced LangChain Features\n",
    "In the [Getting Started notebook](./getting_started.ipynb), we covered an introduction to LangChain and demonstrated how to create a simple Sequential chain. This notebook will cover a smorgasborg of more advanced features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary Python libraries\n",
    "import os\n",
    "import yaml\n",
    "from langchain.chains import ConversationChain, LLMChain\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder, PromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the API key and organization ID from file (NOT pushed to GitHub)\n",
    "with open('../keys/api-keys.yaml') as f:\n",
    "    keys_yaml = yaml.safe_load(f)\n",
    "\n",
    "# Setting the OpenAI API key as an environment variable\n",
    "os.environ['OPENAI_API_KEY'] = keys_yaml['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangSmith Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the environment variables required for LangSmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Advanced LangChain Notebook\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = keys_yaml['LANGCHAIN_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Chatbot Interface with a Custom Role / Tone\n",
    "We're actually going to show how to do this two ways. One is certainly more simple than the other, but some may find the more complicated version to be more flexible to their needs. Even so, the \"complicated\" version isn't all that much more complicated. Let's start with the complicated version and then work our way into the simple version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Complicated Version!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating an LLM (Using OpenAI as our example)\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishing a chat prompt template\n",
    "prompt_template = ChatPromptTemplate(messages = [\n",
    "    \n",
    "    # Setting a customized tone for the chatbot\n",
    "    SystemMessagePromptTemplate.from_template('You answer all questions or inquiries as Jar Jar Binks from Star Wars.'),\n",
    "\n",
    "    # Instantiating a placeholder object that injects any chat history (if present)\n",
    "    MessagesPlaceholder(variable_name = 'chat_history'),\n",
    "\n",
    "    # Defining a human template (We could add more here if we wanted)\n",
    "    HumanMessagePromptTemplate.from_template('{question}')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating an object to hold the memory of the chatbot conversation\n",
    "chat_history = ConversationBufferMemory(memory_key = 'chat_history', return_messages = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the conversation chain using LangChain's LLMChain object and all the configuration information edfined in the above cells\n",
    "conversation_chain = LLMChain(llm = llm,\n",
    "                              prompt = prompt_template,\n",
    "                              memory = chat_history,\n",
    "                              verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You answer all questions or inquiries as Jar Jar Binks from Star Wars.\n",
      "Human: What is the capital of Illinois?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'What is the capital of Illinois?', 'chat_history': [HumanMessage(content='What is the capital of Illinois?', additional_kwargs={}, example=False), AIMessage(content=\"Oh, moi-sa thinkin' the capital of Illinois is Springfield, mesa do!\", additional_kwargs={}, example=False)], 'text': \"Oh, moi-sa thinkin' the capital of Illinois is Springfield, mesa do!\"}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You answer all questions or inquiries as Jar Jar Binks from Star Wars.\n",
      "Human: What is the capital of Illinois?\n",
      "AI: Oh, moi-sa thinkin' the capital of Illinois is Springfield, mesa do!\n",
      "Human: What is the largest city in that state?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'What is the largest city in that state?', 'chat_history': [HumanMessage(content='What is the capital of Illinois?', additional_kwargs={}, example=False), AIMessage(content=\"Oh, moi-sa thinkin' the capital of Illinois is Springfield, mesa do!\", additional_kwargs={}, example=False), HumanMessage(content='What is the largest city in that state?', additional_kwargs={}, example=False), AIMessage(content='Oh, the biggest city in dat state is Chicago, mesa tell ya! Big city, big lights, big fun!', additional_kwargs={}, example=False)], 'text': 'Oh, the biggest city in dat state is Chicago, mesa tell ya! Big city, big lights, big fun!'}\n"
     ]
    }
   ],
   "source": [
    "# Testing out our conversation chain!\n",
    "print(conversation_chain({'question': 'What is the capital of Illinois?'}))\n",
    "print(conversation_chain({'question': 'What is the largest city in that state?'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='What is the capital of Illinois?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content=\"Oh, moi-sa thinkin' the capital of Illinois is Springfield, mesa do!\", additional_kwargs={}, example=False),\n",
       "  HumanMessage(content='What is the largest city in that state?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='Oh, the biggest city in dat state is Chicago, mesa tell ya! Big city, big lights, big fun!', additional_kwargs={}, example=False)]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the chat history\n",
    "chat_history.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Simple Version!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using LangChain's ConversationChain functionality to create a simple chatbot\n",
    "simple_chatbot = ConversationChain(llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What is the capital of Illinois?\n",
      "AI: The capital of Illinois is Springfield. It is located in Sangamon County and is the sixth-most populous city in the state. Springfield is known for its rich history, particularly as the home of President Abraham Lincoln. The city is also a major center for government and healthcare in Illinois.\n",
      "Human: What is the largest city in that state?\n",
      "AI: The largest city in Illinois is Chicago. It is the third-most populous city in the United States, with a population of over 2.7 million people. Chicago is located on the southwestern shore of Lake Michigan and is a major cultural and economic center. The city is known for its iconic skyline, diverse neighborhoods, and vibrant arts scene.\n"
     ]
    }
   ],
   "source": [
    "# Interacting with the simple chatbot\n",
    "prompt_1 = 'What is the capital of Illinois?'\n",
    "print(f'Human: {prompt_1}')\n",
    "print(f'AI: {simple_chatbot.run(prompt_1)}')\n",
    "prompt_2 = 'What is the largest city in that state?'\n",
    "print(f'Human: {prompt_2}')\n",
    "print(f'AI: {simple_chatbot.run(prompt_2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crafting a few shot list of examples\n",
    "few_shot_examples = [\n",
    "    {\n",
    "        'human': 'When I say \"David\", you say \"Hundley.\" From this point forward, double the times you say \"Hundley\" when I say \"David.\" Let\\'s begin. David!',\n",
    "        'ai': 'Hundley!'\n",
    "    },\n",
    "    {\n",
    "        'human': 'David!',\n",
    "        'ai': 'Hundley! Hundley!'\n",
    "    },\n",
    "    {\n",
    "        'human': 'David!',\n",
    "        'ai': 'Hundley! Hundley! Hundley!'\n",
    "    },\n",
    "    {\n",
    "        'human': 'David!',\n",
    "        'ai': 'Hundley! Hundley! Hundley! Hundley!'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining how the few shot examples we'll be passing in are structured\n",
    "few_shot_structure = ChatPromptTemplate.from_messages(\n",
    "    [('human', '{human}'), ('ai', '{ai}')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: When I say \"David\", you say \"Hundley.\" From this point forward, double the times you say \"Hundley\" when I say \"David.\" Let's begin. David!\n",
      "AI: Hundley!\n",
      "Human: David!\n",
      "AI: Hundley! Hundley!\n",
      "Human: David!\n",
      "AI: Hundley! Hundley! Hundley!\n",
      "Human: David!\n",
      "AI: Hundley! Hundley! Hundley! Hundley!\n"
     ]
    }
   ],
   "source": [
    "# Defining the few shot prompt from the structure and examples defined above\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples = few_shot_examples,\n",
    "    example_prompt = few_shot_structure\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the few shot prompt as a precursor to interacting with the LLM\n",
    "final_prompt = ChatPromptTemplate.from_messages([few_shot_prompt, ('human', '{input}')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating an LLM (Using OpenAI as our example)\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hundley! Hundley! Hundley! Hundley! Hundley!', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passing in our few shot prompt along with an additional human prompt into the LLM\n",
    "llm(messages = final_prompt.format_prompt(input = 'David!').to_messages())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routing Based on Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting templates for each of our routes\n",
    "jar_jar_template = 'You are Jar Jar Binks from Star Wars and answer any questions / inquiries as Jar Jar. Here is the input prompt: {input}'\n",
    "hagrid_template = 'You are Hagrid from Harry Potter and answer any questions / inquiries as Hagrid. Here is the input prompt: {input}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a prompt matching template\n",
    "prompt_matching_template = [\n",
    "    {\n",
    "        'name': 'star_wars',\n",
    "        'description': 'Useful for answering any questions about the Star Wars series',\n",
    "        'prompt_template': jar_jar_template\n",
    "    },\n",
    "    {\n",
    "        'name': 'harry_potter',\n",
    "        'description': 'Useful for answering any questions about the Harry Potter series',\n",
    "        'prompt_template': hagrid_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting an LLM to use\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformatting the destination chains\n",
    "destination_chains = {}\n",
    "for p_info in prompt_matching_template:\n",
    "    name = p_info['name']\n",
    "    prompt_template = p_info['prompt_template']\n",
    "    prompt = PromptTemplate(template = prompt_template, input_variables = ['input'])\n",
    "    chain = LLMChain(llm = llm, prompt = prompt)\n",
    "    destination_chains[name] = chain\n",
    "\n",
    "# Setting a default chain\n",
    "default_chain = ConversationChain(llm = llm, output_key = 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the router chain\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_matching_template]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations = destinations_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the router prompt based on the router template\n",
    "router_prompt = PromptTemplate(\n",
    "    template = router_template,\n",
    "    input_variables = ['input'],\n",
    "    output_parser = RouterOutputParser(),\n",
    ")\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a multiprompt chain around the router chain\n",
    "multiprompt_chain = MultiPromptChain(\n",
    "    router_chain = router_chain,\n",
    "    destination_chains = destination_chains,\n",
    "    default_chain = default_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Wars Test Prompt: Who is Anakin Skywalker?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, meesa know Anakin Skywalker! Heesa a very special and talented young boy, mesa tell you! Anakin, heesa a Jedi Knight, heesa a hero! Heesa from Tatooine, just like meesa. Anakin, heesa the chosen one, destined to bring balance to the Force. Mesa had the honor of meeting him and becoming his friend! Anakin, heesa strong, brave, and full of hope. But, mesa must warn you, heesa also faced many challenges and temptations. Hisesa journey, it's a very important part of the Star Wars saga, it is, muy muy important!\n",
      "\n",
      "Harry Potter Test Prompt: Who is Hermione Granger?\n",
      "Ah, Hermione Granger! She's a bright young witch, she is. Hermione is one of Harry Potter's best friends and a truly remarkable girl. She's got a brain the size of a mountain and a heart full of courage. Hermione is known for her exceptional intelligence and her love for books and learning. She's always got her nose stuck in one book or another, constantly expanding her knowledge about magic and all sorts of subjects.\n",
      "\n",
      "Hermione's a real go-getter and fiercely loyal to her friends. She's helped Harry and Ron countless times with her quick thinking and clever spellwork. She's got a knack for getting them out of tight spots, I tell ya!\n",
      "\n",
      "But it ain't just her brains that make her special. Hermione's got a big heart, too. She cares deeply about fairness and fighting for what's right. She's never afraid to stand up against injustice, even if it means going against authority. And let me tell ya, she's got a mean right hook when she needs it!\n",
      "\n",
      "All in all, Hermione Granger is a true hero in her own right. She's a force to be reckoned with, and I'm proud to call her a friend.\n",
      "\n",
      "Generic Test Prompt: What is the capital of Illinois?\n",
      "The capital of Illinois is Springfield. It is located in the central part of the state. Springfield is known for being the hometown of former President Abraham Lincoln and is home to many historic sites related to his life and presidency.\n"
     ]
    }
   ],
   "source": [
    "# Testing out the router chain!\n",
    "star_wars_prompt = 'Who is Anakin Skywalker?'\n",
    "print(f'Star Wars Test Prompt: {star_wars_prompt}')\n",
    "print(multiprompt_chain.run(star_wars_prompt))\n",
    "\n",
    "harry_potter_prompt = 'Who is Hermione Granger?'\n",
    "print(f'\\nHarry Potter Test Prompt: {harry_potter_prompt}')\n",
    "print(multiprompt_chain.run(harry_potter_prompt))\n",
    "\n",
    "generic_prompt = 'What is the capital of Illinois?'\n",
    "print(f'\\nGeneric Test Prompt: {generic_prompt}')\n",
    "print(multiprompt_chain.run(generic_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a simple OpenAI LLM chain\n",
    "llm_chain = LLMChain(llm = OpenAI(), prompt = PromptTemplate(template = '{question}', input_variables = [\"question\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Rachel Green\n",
      "2. Ross Geller\n",
      "3. Monica Geller\n",
      "4. Chandler Bing\n",
      "5. Joey Tribbiani\n"
     ]
    }
   ],
   "source": [
    "# Viewing the standard output\n",
    "response = llm_chain.run('Who are the five main characters from the TV show Friends?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a list parsing object\n",
    "list_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-instantiating the chain with the list parsing output\n",
    "llm_chain = LLMChain(\n",
    "    llm = OpenAI(),\n",
    "    prompt = PromptTemplate(\n",
    "        template = '{question}\\n{format_instructions}',\n",
    "        input_variables = ['question'],\n",
    "        partial_variables = {'format_instructions': list_parser.get_format_instructions()}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monica Geller',\n",
       " 'Chandler Bing',\n",
       " 'Ross Geller',\n",
       " 'Rachel Green',\n",
       " 'Joey Tribbiani']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the newly formatted output\n",
    "response = list_parser.parse(llm_chain.run('Who are the five main characters from the TV show Friends?'))\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
