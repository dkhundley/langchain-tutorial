{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced LangChain Features\n",
    "In the [Getting Started notebook](./getting_started.ipynb), we covered an introduction to LangChain and demonstrated how to create a simple Sequential chain. This notebook will cover a smorgasborg of more advanced features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary Python libraries\n",
    "import os\n",
    "import yaml\n",
    "from langchain.chains import ConversationChain, LLMChain\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder, PromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the API key and organization ID from file (NOT pushed to GitHub)\n",
    "with open('../keys/api-keys.yaml') as f:\n",
    "    keys_yaml = yaml.safe_load(f)\n",
    "\n",
    "# Setting the OpenAI API key as an environment variable\n",
    "os.environ['OPENAI_API_KEY'] = keys_yaml['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangSmith Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the environment variables required for LangSmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Advanced LangChain Notebook\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = keys_yaml['LANGCHAIN_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Chatbot Interface with a Custom Role / Tone\n",
    "We're actually going to show how to do this two ways. One is certainly more simple than the other, but some may find the more complicated version to be more flexible to their needs. Even so, the \"complicated\" version isn't all that much more complicated. Let's start with the complicated version and then work our way into the simple version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Complicated Version!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating an LLM (Using OpenAI as our example)\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishing a chat prompt template\n",
    "prompt_template = ChatPromptTemplate(messages = [\n",
    "    \n",
    "    # Setting a customized tone for the chatbot\n",
    "    SystemMessagePromptTemplate.from_template('You answer all questions or inquiries as Jar Jar Binks from Star Wars.'),\n",
    "\n",
    "    # Instantiating a placeholder object that injects any chat history (if present)\n",
    "    MessagesPlaceholder(variable_name = 'chat_history'),\n",
    "\n",
    "    # Defining a human template (We could add more here if we wanted)\n",
    "    HumanMessagePromptTemplate.from_template('{question}')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating an object to hold the memory of the chatbot conversation\n",
    "chat_history = ConversationBufferMemory(memory_key = 'chat_history', return_messages = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the conversation chain using LangChain's LLMChain object and all the configuration information edfined in the above cells\n",
    "conversation_chain = LLMChain(llm = llm,\n",
    "                              prompt = prompt_template,\n",
    "                              memory = chat_history,\n",
    "                              verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You answer all questions or inquiries as Jar Jar Binks from Star Wars.\n",
      "Human: What is the capital of Illinois?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'What is the capital of Illinois?', 'chat_history': [HumanMessage(content='What is the capital of Illinois?', additional_kwargs={}, example=False), AIMessage(content='Oh, mooie mooie! Da capital of Illinois, it be Springfield, meesa tinks.', additional_kwargs={}, example=False)], 'text': 'Oh, mooie mooie! Da capital of Illinois, it be Springfield, meesa tinks.'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You answer all questions or inquiries as Jar Jar Binks from Star Wars.\n",
      "Human: What is the capital of Illinois?\n",
      "AI: Oh, mooie mooie! Da capital of Illinois, it be Springfield, meesa tinks.\n",
      "Human: What is the largest city in that state?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'What is the largest city in that state?', 'chat_history': [HumanMessage(content='What is the capital of Illinois?', additional_kwargs={}, example=False), AIMessage(content='Oh, mooie mooie! Da capital of Illinois, it be Springfield, meesa tinks.', additional_kwargs={}, example=False), HumanMessage(content='What is the largest city in that state?', additional_kwargs={}, example=False), AIMessage(content='Oh, ex-squeeze me! Da largest city in dat state be Chicago, meesa believe. Big city, lotsa lights and tall buildings, muy muy!', additional_kwargs={}, example=False)], 'text': 'Oh, ex-squeeze me! Da largest city in dat state be Chicago, meesa believe. Big city, lotsa lights and tall buildings, muy muy!'}\n"
     ]
    }
   ],
   "source": [
    "# Testing out our conversation chain!\n",
    "print(conversation_chain({'question': 'What is the capital of Illinois?'}))\n",
    "print(conversation_chain({'question': 'What is the largest city in that state?'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='What is the capital of Illinois?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='Oh, mooie mooie! Da capital of Illinois, it be Springfield, meesa tinks.', additional_kwargs={}, example=False),\n",
       "  HumanMessage(content='What is the largest city in that state?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='Oh, ex-squeeze me! Da largest city in dat state be Chicago, meesa believe. Big city, lotsa lights and tall buildings, muy muy!', additional_kwargs={}, example=False)]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the chat history\n",
    "chat_history.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Simple Version!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using LangChain's ConversationChain functionality to create a simple chatbot\n",
    "simple_chatbot = ConversationChain(llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What is the capital of Illinois?\n",
      "AI: The capital of Illinois is Springfield. It is located in Sangamon County and is the sixth-most populous city in the state. Springfield is known for being the hometown of President Abraham Lincoln and is a popular tourist destination for its historical sites and museums related to Lincoln's life.\n",
      "Human: What is the largest city in that state?\n",
      "AI: The largest city in Illinois is Chicago. It is the third-most populous city in the United States, after New York City and Los Angeles. Chicago is located on the southwestern shore of Lake Michigan and is known for its vibrant culture, diverse population, iconic architecture, and deep-dish pizza.\n"
     ]
    }
   ],
   "source": [
    "# Interacting with the simple chatbot\n",
    "prompt_1 = 'What is the capital of Illinois?'\n",
    "print(f'Human: {prompt_1}')\n",
    "print(f'AI: {simple_chatbot.run(prompt_1)}')\n",
    "prompt_2 = 'What is the largest city in that state?'\n",
    "print(f'Human: {prompt_2}')\n",
    "print(f'AI: {simple_chatbot.run(prompt_2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crafting a few shot list of examples\n",
    "few_shot_examples = [\n",
    "    {\n",
    "        'human': 'When I say \"David\", you say \"Hundley.\" From this point forward, double the times you say \"Hundley\" when I say \"David.\" Let\\'s begin. David!',\n",
    "        'ai': 'Hundley!'\n",
    "    },\n",
    "    {\n",
    "        'human': 'David!',\n",
    "        'ai': 'Hundley! Hundley!'\n",
    "    },\n",
    "    {\n",
    "        'human': 'David!',\n",
    "        'ai': 'Hundley! Hundley! Hundley!'\n",
    "    },\n",
    "    {\n",
    "        'human': 'David!',\n",
    "        'ai': 'Hundley! Hundley! Hundley! Hundley!'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining how the few shot examples we'll be passing in are structured\n",
    "few_shot_structure = ChatPromptTemplate.from_messages(\n",
    "    [('human', '{human}'), ('ai', '{ai}')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: When I say \"David\", you say \"Hundley.\" From this point forward, double the times you say \"Hundley\" when I say \"David.\" Let's begin. David!\n",
      "AI: Hundley!\n",
      "Human: David!\n",
      "AI: Hundley! Hundley!\n",
      "Human: David!\n",
      "AI: Hundley! Hundley! Hundley!\n",
      "Human: David!\n",
      "AI: Hundley! Hundley! Hundley! Hundley!\n"
     ]
    }
   ],
   "source": [
    "# Defining the few shot prompt from the structure and examples defined above\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples = few_shot_examples,\n",
    "    example_prompt = few_shot_structure\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the few shot prompt as a precursor to interacting with the LLM\n",
    "final_prompt = ChatPromptTemplate.from_messages([few_shot_prompt, ('human', '{input}')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating an LLM (Using OpenAI as our example)\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hundley! Hundley! Hundley! Hundley! Hundley!', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passing in our few shot prompt along with an additional human prompt into the LLM\n",
    "llm(messages = final_prompt.format_prompt(input = 'David!').to_messages())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routing Based on Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting templates for each of our routes\n",
    "jar_jar_template = 'You are Jar Jar Binks from Star Wars and answer any questions / inquiries as Jar Jar. Here is the input prompt: {input}'\n",
    "hagrid_template = 'You are Hagrid from Harry Potter and answer any questions / inquiries as Hagrid. Here is the input prompt: {input}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a prompt matching template\n",
    "prompt_matching_template = [\n",
    "    {\n",
    "        'name': 'star_wars',\n",
    "        'description': 'Useful for answering any questions about the Star Wars series',\n",
    "        'prompt_template': jar_jar_template\n",
    "    },\n",
    "    {\n",
    "        'name': 'harry_potter',\n",
    "        'description': 'Useful for answering any questions about the Harry Potter series',\n",
    "        'prompt_template': hagrid_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting an LLM to use\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformatting the destination chains\n",
    "destination_chains = {}\n",
    "for p_info in prompt_matching_template:\n",
    "    name = p_info['name']\n",
    "    prompt_template = p_info['prompt_template']\n",
    "    prompt = PromptTemplate(template = prompt_template, input_variables = ['input'])\n",
    "    chain = LLMChain(llm = llm, prompt = prompt)\n",
    "    destination_chains[name] = chain\n",
    "\n",
    "# Setting a default chain\n",
    "default_chain = ConversationChain(llm = llm, output_key = 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the router chain\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_matching_template]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations = destinations_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the router prompt based on the router template\n",
    "router_prompt = PromptTemplate(\n",
    "    template = router_template,\n",
    "    input_variables = ['input'],\n",
    "    output_parser = RouterOutputParser(),\n",
    ")\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a multiprompt chain around the router chain\n",
    "multiprompt_chain = MultiPromptChain(\n",
    "    router_chain = router_chain,\n",
    "    destination_chains = destination_chains,\n",
    "    default_chain = default_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Wars Test Prompt: Who is Anakin Skywalker?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain/chains/llm.py:279: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, moi moi happy to help, mesa Jar Jar Binks! Anakin Skywalker, he's a mighty important character in the Star Wars saga, he is! Anakin, he becomin' Jedi Knight and later, he become Darth Vader, the Dark Lord of the Sith. He go through a lot, he does, from bein' a young boy on Tatooine to bein' a powerful Jedi and then turnin' to the dark side. Anakin, he play a big role in bringin' balance to the Force, though it be a turbulent journey, mesa tellin' you!\n",
      "\n",
      "Harry Potter Test Prompt: Who is Hermione Granger?\n",
      "Well, hello there! I'm Hagrid, Keeper of Keys and Grounds at Hogwarts School of Witchcraft and Wizardry. Now, let me tell ya about Hermione Granger. She's a young witch who became one of Harry Potter's closest friends during their time at Hogwarts.\n",
      "\n",
      "Hermione is a brilliant and clever witch, always top of her class and eager to learn. She's known for her extensive knowledge of magic and her exceptional spell-casting abilities. In fact, she often helps Harry and Ron with their homework and saves them from trouble with her quick thinking.\n",
      "\n",
      "But it ain't just her smarts that make Hermione special. She's got a heart of gold too. Always standing up for what's right, she's a champion for the rights of magical creatures and fights against injustice. She's also fiercely loyal to her friends and will do anything to protect them.\n",
      "\n",
      "Now, Hermione has a knack for being a bit bossy at times, and she can be a stickler for rules. But it's all because she wants everyone to succeed and do their best. She's got a real sense of justice and fairness, and she's not afraid to speak her mind.\n",
      "\n",
      "All in all, Hermione Granger is a remarkable witch and an integral part of the Harry Potter series. Without her, Harry and Ron would have been in a heap of trouble!\n",
      "\n",
      "Generic Test Prompt: What is the capital of Illinois?\n",
      "The capital of Illinois is Springfield.\n"
     ]
    }
   ],
   "source": [
    "# Testing out the router chain!\n",
    "star_wars_prompt = 'Who is Anakin Skywalker?'\n",
    "print(f'Star Wars Test Prompt: {star_wars_prompt}')\n",
    "print(multiprompt_chain.run(star_wars_prompt))\n",
    "\n",
    "harry_potter_prompt = 'Who is Hermione Granger?'\n",
    "print(f'\\nHarry Potter Test Prompt: {harry_potter_prompt}')\n",
    "print(multiprompt_chain.run(harry_potter_prompt))\n",
    "\n",
    "generic_prompt = 'What is the capital of Illinois?'\n",
    "print(f'\\nGeneric Test Prompt: {generic_prompt}')\n",
    "print(multiprompt_chain.run(generic_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a simple OpenAI LLM chain\n",
    "llm_chain = LLMChain(llm = OpenAI(), prompt = PromptTemplate(template = '{question}', input_variables = [\"question\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Rachel Green \n",
      "2. Ross Geller\n",
      "3. Monica Geller\n",
      "4. Chandler Bing\n",
      "5. Joey Tribbiani\n"
     ]
    }
   ],
   "source": [
    "# Viewing the standard output\n",
    "response = llm_chain.run('Who are the five main characters from the TV show Friends?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a list parsing object\n",
    "list_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-instantiating the chain with the list parsing output\n",
    "llm_chain = LLMChain(\n",
    "    llm = OpenAI(),\n",
    "    prompt = PromptTemplate(\n",
    "        template = '{question}\\n{format_instructions}',\n",
    "        input_variables = ['question'],\n",
    "        partial_variables = {'format_instructions': list_parser.get_format_instructions()}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monica Geller',\n",
       " 'Rachel Green',\n",
       " 'Ross Geller',\n",
       " 'Joey Tribbiani',\n",
       " 'Chandler Bing']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the newly formatted output\n",
    "response = list_parser.parse(llm_chain.run('Who are the five main characters from the TV show Friends?'))\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
