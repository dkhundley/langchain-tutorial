{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vid2Blog\n",
    "\n",
    "This notebook was instigated by [a xeet posted by Andrej Karpathy](https://twitter.com/karpathy/status/1760740503614836917). Throughout this notebook, we will attempt to take a longform video and automatedly transform it into a blog post.\n",
    "\n",
    "## \"Business\" Strategy\n",
    "The strategy for enabling this will evolve over time, but here is what I am thinking as of right now:\n",
    "\n",
    "- Use the OpenAI Whisper API to transcribe the audio from the video.\n",
    "- Use LLM to break the transcription into logical segments.\n",
    "- Determine the timestamp chunks from the previous step's segmentated script.\n",
    "- Use something (there's gotta be something!) to automatedly break the video into chunks.\n",
    "- Extract frames at regular intervals and save them to disk for later use (This is tough to get right...)\n",
    "- Use LLM to summarize the segmented into an outline **in JSON form**. (Important to get it in a structured form for the next steps.)\n",
    "- In parallel, produce each segment of the blog post by passing in the following info in each parallel call:\n",
    "    - The full outline (Maybe this needs converted back from JSON into plaintext?)\n",
    "    - The transcribed text from that particular section\n",
    "    - GPT-V uses the images to give a better description of what's going on (Again, hard problem)\n",
    "- Run the full blog post back through the LLM for \"final clean up\", ensuring cohesion and proper attributions are moved to the end of the post\n",
    "\n",
    "## Technical Strategy\n",
    "Let's takes the steps that we derived in the strategy above and start to write out a plan for making this happen:\n",
    "\n",
    "1. Programmatically download the video from YouTube. (Idk how to do this, but I'm sure there's a Python client that'll do the job.)\n",
    "    - Side step: Check to see if the video is already downloaded. If yes, use \"cached\" video.\n",
    "2. Separate the audio from the video and save it as an mp3 (?) file.\n",
    "3. Pass the audio into OpenAI's whisper API. (And save the transcript so I'm not breaking my bank by running that thing too much ðŸ˜‚)\n",
    "4. Use GPT-4 to break the audio into segments (Will need to do a bit of prompt engineering here)\n",
    "5. Somehow make that connection to determine how the timestamps align to each segment (tricky tricky...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup\n",
    "Let's do our imports and such!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_community.document_loaders import YoutubeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading my personal OpenAI API key\n",
    "with open('../keys/api-keys.yaml', 'r') as f:\n",
    "    API_KEYS = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting some constants\n",
    "YOUTUBE_URL = 'https://youtu.be/zduSFxRajkE?si=4sptfAH4EQq4_-gW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throwing in some special utilities to test around with for now. Will remove them later (maybe)\n",
    "import tiktoken\n",
    "token_estimator = tiktoken.encoding_for_model('gpt-4')\n",
    "\n",
    "COST_PER_1K = .01\n",
    "\n",
    "def calculate_cost(num_tokens, cost_per_1k_tokens):\n",
    "    print((num_tokens / 1000) * cost_per_1k_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Setup\n",
    "Throughout this project, I'm going to attempt to make use of **LangChain**. Because we need to instantiate a bunch of stuff, let's just go ahead and knock that out now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the OpenAI LLM client with LangChain\n",
    "llm = ChatOpenAI(\n",
    "    api_key = API_KEYS['OPENAI_API_KEY'],\n",
    "    model_name = 'gpt-4-1106-preview',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the Video from YouTube\n",
    "Wouldn't you know, LangChain has an integration to support this! It is using **pytube** behind the scenes, so you will need to install that if you haven't already. (`pip install pytube`) We also need to figure out a way to save the video as a cache, just to save us a bit of a headache as we do our work.\n",
    "\n",
    "*Actually...*\n",
    "\n",
    "It looks like YouTube has a transcript API. I still think there's value in trying Whisper, but just for now, I'm curious how far I can get with this transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the transcript from the YouTube video\n",
    "yt_transcript_loader = YoutubeLoader.from_youtube_url(youtube_url = YOUTUBE_URL)\n",
    "yt_transcript = yt_transcript_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of tokens: 26299\n"
     ]
    }
   ],
   "source": [
    "# Estimating number of tokens to pass in full prompt to GPT-4\n",
    "estimated_tokens = token_estimator.encode(yt_transcript[0].page_content)\n",
    "print(f'Estimated number of tokens: {len(estimated_tokens)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26299\n"
     ]
    }
   ],
   "source": [
    "calculate_cost(num_tokens = len(estimated_tokens), cost_per_1k_tokens = COST_PER_1K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
